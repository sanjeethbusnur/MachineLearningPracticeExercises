{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDL_Assignment_7.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "H1QUPNbC1jid",
        "fABE6wCL4ycv",
        "Z40b8YaJTTmy",
        "W9PxdAkk7sjs",
        "GIgWchqHoOUk",
        "os1BQH6gNUfe",
        "YksPE1mHcNG5",
        "7YsowfbwiFMC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60cnkg4NlyWV",
        "colab_type": "text"
      },
      "source": [
        "**Assignment - 7**\n",
        "\n",
        "**Team Members:**\n",
        "\n",
        "1. Sanjeeth Busnur Indushekar: 224133 : sanjeeth.busnur@st.ovgu.de\n",
        "\n",
        "2. Aditya Dey : 230580 : aditya.dey@st.ovgu.de\n",
        "\n",
        "3. Suraj Shashidhar: 230052 : suraj.shashidhar@st.ovgu.de"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STbYFNjHwbx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiDYWj6ticWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "fc44cd9f-2354-43b5-9fe5-1a77d6a02f2a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLWcPG14ioly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU8HHg-jishI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Colab Notebooks')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1QUPNbC1jid",
        "colab_type": "text"
      },
      "source": [
        "# Task-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX8has2gxS3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def top_k_values(Input,k):\n",
        "  top_k = tf.math.top_k(input=Input,k=k,sorted=False)\n",
        "  return top_k.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFGWD3SSzJOc",
        "colab_type": "code",
        "outputId": "71fdd5fc-ad98-4fa7-a330-555327688c7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "Input = tf.reshape(np.arange(25),[5,5])\n",
        "Input.numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  3,  4],\n",
              "       [ 5,  6,  7,  8,  9],\n",
              "       [10, 11, 12, 13, 14],\n",
              "       [15, 16, 17, 18, 19],\n",
              "       [20, 21, 22, 23, 24]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3uk0Poaz5XD",
        "colab_type": "code",
        "outputId": "e3e09081-041b-4a55-d074-31db5528a1ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "tf.print(top_k_values(Input,3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2 3 4]\n",
            " [7 8 9]\n",
            " [12 13 14]\n",
            " [17 18 19]\n",
            " [22 23 24]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fABE6wCL4ycv",
        "colab_type": "text"
      },
      "source": [
        "# Task-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kKQMZ4k416y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def one_hot_argmax(Input):\n",
        "  argmax = tf.math.argmax(input=Input,axis=1)\n",
        "  return tf.one_hot(argmax,depth=Input.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoLil41u6M6i",
        "colab_type": "code",
        "outputId": "2ff08bba-cdab-4bdc-e341-6db9b7f963ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "Input = tf.random.uniform((6,4),minval=1,maxval=25,dtype=tf.dtypes.int32)\n",
        "Input.numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3, 11, 15, 14],\n",
              "       [ 7,  9, 14,  3],\n",
              "       [ 4,  5, 23, 20],\n",
              "       [14,  1,  1, 13],\n",
              "       [ 7, 20, 12,  4],\n",
              "       [16, 16,  6, 11]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4SykPmI6SYK",
        "colab_type": "code",
        "outputId": "b63c36d6-ea6d-4f1f-8ae7-87458eb30c64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "tf.print(one_hot_argmax(Input))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [1 0 0 0]\n",
            " [0 1 0 0]\n",
            " [1 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z40b8YaJTTmy",
        "colab_type": "text"
      },
      "source": [
        "# Task-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-GHaO3FVSu5",
        "colab_type": "text"
      },
      "source": [
        "**One Dimensional Array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwizvdM4TYZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def scatter(Input,k):\n",
        "  new_arr = tf.math.top_k(Input,k=k)\n",
        "  indices = tf.expand_dims(new_arr.indices,axis=1)\n",
        "  scatter = tf.scatter_nd(indices=indices,updates=new_arr.values,shape=Input.shape)\n",
        "  return scatter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoHDj9ubULAM",
        "colab_type": "code",
        "outputId": "f4d791bf-1dba-4444-eb9a-c96ada0e8847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Input = tf.random.uniform((5,),minval=1,maxval=25,dtype=tf.dtypes.int32)\n",
        "tf.print(Input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 3 9 23 14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apjmRF73VD-l",
        "colab_type": "code",
        "outputId": "b22419a5-f525-46b3-86a3-e8bd3ca487bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.print(scatter(Input,3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 9 23 14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leX8A2cnVdld",
        "colab_type": "text"
      },
      "source": [
        "**Two Dimensional Array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8bDZK3BVjLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def scatter_2d(Input, k):\n",
        "  shape = Input.shape\n",
        "  new_arr = tf.math.top_k(Input,k=k)\n",
        "  indices = new_arr.indices\n",
        "  values = new_arr.values\n",
        "  num_rows = Input.shape[0]\n",
        "  row_range = tf.range(num_rows)\n",
        "  tensor_row = tf.tile(row_range[:,None], (1, k))\n",
        "  top_k_row_col_idxs = tf.stack([tensor_row, indices], axis=2)\n",
        "  updates = tf.ones([num_rows, k], dtype=tf.int32)\n",
        "  zero_mask = tf.scatter_nd(top_k_row_col_idxs, updates, shape)\n",
        "  scatter = Input * zero_mask\n",
        "  return scatter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQE_Rb7cXPSK",
        "colab_type": "code",
        "outputId": "4a0cade4-3e1a-475b-9ad9-3463823381dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "Input = tf.random.uniform((5,5),minval=1,maxval=50,dtype=tf.dtypes.int32)\n",
        "tf.print(Input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[17 1 12 19 32]\n",
            " [25 4 40 44 40]\n",
            " [37 36 18 40 39]\n",
            " [21 4 11 40 21]\n",
            " [36 29 5 37 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJxuO3dXXon1",
        "colab_type": "code",
        "outputId": "f1a1c93a-7f3e-411b-e47a-131f23bce32b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "tf.print(scatter_2d(Input, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[17 0 0 19 32]\n",
            " [0 0 40 44 40]\n",
            " [37 0 0 40 39]\n",
            " [21 0 0 40 21]\n",
            " [36 29 0 37 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "921MQ4_sYiob",
        "colab_type": "text"
      },
      "source": [
        "Reference:\n",
        "1. https://stackoverflow.com/questions/52996505/using-scatter-nd-with-top-k-output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9PxdAkk7sjs",
        "colab_type": "text"
      },
      "source": [
        "# Task-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-vA-Za9MM0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def exp_mov_avg(Input,a):\n",
        "  new = tf.TensorArray(tf.float32, size=0, dynamic_size=True,clear_after_read=False)\n",
        "  new = new.write(0,Input[0])\n",
        "  for i in tf.range(1,Input.shape[0]):\n",
        "    new = new.write(i,(a*new.read(i-1))+((1-a)*Input[i]))\n",
        "  return new.stack()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c5JnE3w_g9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Input = tf.constant([1,2,3,4,5],dtype=float)\n",
        "a = tf.constant(0.15,dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA61UbYmEd7d",
        "colab_type": "code",
        "outputId": "8d4846f9-3d18-4383-e8d6-7eb4f7b0d91e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.print(exp_mov_avg(Input,a))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1.85 2.8275 3.82412505 4.82361889]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw5SQ62dmlYd",
        "colab_type": "text"
      },
      "source": [
        "# Task-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E84oCgh8mpC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5th task didnt know to find it for nth term.\n",
        "def exp_mov_avg_last(input, a):\n",
        "\n",
        "    n = int(-100. / np.log(a)) # Makes sure that the first and last elements in f are very big and very small (about 1e22 and 1e-22)\n",
        "    f = np.exp(np.arange(1-n, n, 2) * (0.5 * np.log(a))) # Scaling factor for each slice\n",
        "    tmp = (np.resize(input, ((len(input) + n - 1) // n, n)) / f * (1. - a)).cumsum(axis=1) * f # Get ewm for each slice of length n\n",
        "\n",
        "    # Add the last value of each previous slice to the next slice with corresponding scaling factor f and return result\n",
        "    return np.resize(tmp + np.tensordot(np.append(input[0], np.roll(tmp.T[n-1], 1)[1:]), f * ((a) / f[0]), axes=0), len(input))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-VVTz9emrAQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c785d12c-8f97-4a08-ad78-0d12e3fdbd27"
      },
      "source": [
        "input = [1.,2.,3.,4.,5.,6.]\n",
        "a = 0.20\n",
        "tf.print(\"================= Input before calculating Exponentially moving Average =================== \\n\")\n",
        "tf.print(input)\n",
        "tf.print(\"================= Last Output after calculating Exponentially moving Average =================== \\n\")\n",
        "output = task5(input,a)\n",
        "tf.print(output[-1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================= Input before calculating Exponentially moving Average =================== \n",
            "\n",
            "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
            "================= Last Output after calculating Exponentially moving Average =================== \n",
            "\n",
            "5.750080000000003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUgKaRY3m5d4",
        "colab_type": "text"
      },
      "source": [
        "Reference: https://stackoverflow.com/questions/42869495/numpy-version-of-exponential-weighted-moving-average-equivalent-to-pandas-ewm "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIgWchqHoOUk",
        "colab_type": "text"
      },
      "source": [
        "# Task - 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fqlCe2SoQ4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def even_odd(x,y,z):\n",
        "  original_shape = x.shape\n",
        "  x = tf.unstack(tf.reshape(x, [-1]))\n",
        "  y = tf.unstack(tf.reshape(y, [-1]))\n",
        "  z = tf.unstack(tf.reshape(z, [-1]))\n",
        "  new_arr = tf.TensorArray(dtype=tf.int32,size=0,dynamic_size=True,clear_after_read=False)\n",
        "  for i,m in enumerate(x):\n",
        "    if (m % 2 == 0):\n",
        "      new_arr = new_arr.write(i,y[i])  \n",
        "    else:\n",
        "       new_arr = new_arr.write(i,z[i]) \n",
        "  return (tf.reshape(new_arr.stack(),shape=original_shape))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irq_nZZRL5fL",
        "colab_type": "code",
        "outputId": "32b050bf-7f10-47f5-a0ed-f74cb010de94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "x = tf.random.uniform((2,3,3),minval=0,maxval=100,dtype=tf.dtypes.int32)\n",
        "y = tf.random.uniform((2,3,3),minval=0,maxval=100,dtype=tf.dtypes.int32)\n",
        "z = tf.random.uniform((2,3,3),minval=0,maxval=100,dtype=tf.dtypes.int32)\n",
        "tf.print('x: ', x)\n",
        "tf.print('\\n')\n",
        "tf.print('y: ', y)\n",
        "tf.print('\\n')\n",
        "tf.print('z: ', z)\n",
        "tf.print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x:  [[[37 97 99]\n",
            "  [94 28 81]\n",
            "  [53 16 83]]\n",
            "\n",
            " [[15 32 45]\n",
            "  [10 1 3]\n",
            "  [60 41 21]]]\n",
            "\n",
            "\n",
            "y:  [[[48 88 77]\n",
            "  [8 45 86]\n",
            "  [81 78 31]]\n",
            "\n",
            " [[84 87 79]\n",
            "  [79 97 16]\n",
            "  [59 81 79]]]\n",
            "\n",
            "\n",
            "z:  [[[8 61 42]\n",
            "  [91 20 78]\n",
            "  [53 70 11]]\n",
            "\n",
            " [[32 32 25]\n",
            "  [67 39 86]\n",
            "  [54 18 70]]]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrRWSkz_MZd3",
        "colab_type": "code",
        "outputId": "cea1caf6-9f8f-4434-c542-049ecb080948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "tf.print(even_odd(x,y,z))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[8 61 42]\n",
            "  [8 45 78]\n",
            "  [53 78 11]]\n",
            "\n",
            " [[32 87 25]\n",
            "  [79 39 86]\n",
            "  [59 18 70]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os1BQH6gNUfe",
        "colab_type": "text"
      },
      "source": [
        "# Task-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tszCWSCNWiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def last_dimension(Input):\n",
        "  last_dims = Input.shape[-1]\n",
        "  if (last_dims > 100):\n",
        "    return 100\n",
        "  elif (last_dims <= 100 and last_dims > 44):\n",
        "    return 12\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk8rkK_pPb3k",
        "colab_type": "code",
        "outputId": "efc43737-7462-4d41-ff11-1e1a7b4f1bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Input = tf.random.uniform(shape=(4,6,15,45),minval=1,maxval=1000)\n",
        "tf.print(last_dimension(Input))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YksPE1mHcNG5",
        "colab_type": "text"
      },
      "source": [
        "# Task-8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCL7tRW5ZM57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c1 = tf.Variable(0)\n",
        "c2 = tf.Variable(0)\n",
        "c3 = tf.Variable(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1I9Zv76ZxCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def last_dimension(Input):\n",
        "  global c1,c2,c3\n",
        "  last_dims = Input.shape[-1]\n",
        "  if (last_dims > 100):\n",
        "    c1.assign_add(1)\n",
        "    return 100\n",
        "  elif (last_dims <= 100 and last_dims > 44):\n",
        "    c2.assign_add(1)\n",
        "    return 12\n",
        "  else:\n",
        "    c3.assign_add(1)\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKELg5vsaCKk",
        "colab_type": "code",
        "outputId": "c3362489-7560-494b-feba-83388310f26b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "Input = tf.random.uniform(shape=(3,2,145),minval=1,maxval=100)\n",
        "for m in tf.range(5):\n",
        "   last_dimension(Input)\n",
        "tf.print(c1,c2,c3)\n",
        "\n",
        "Input = tf.random.uniform(shape=(4,5,77),minval=1,maxval=100)\n",
        "for m in tf.range(15):\n",
        "   last_dimension(Input)\n",
        "tf.print(c1,c2,c3)\n",
        "\n",
        "Input = tf.random.uniform(shape=(7,8,7),minval=1,maxval=100)\n",
        "for m in tf.range(10):\n",
        "   last_dimension(Input)\n",
        "tf.print(c1,c2,c3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 0 0\n",
            "5 15 0\n",
            "5 15 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-SQoXCKQqI4",
        "colab_type": "text"
      },
      "source": [
        "# Task-9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P_HmpmqQsjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def n_n_Tensor(x,y):\n",
        "  return x[:,None]-y[None,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iONe3AgyRYHh",
        "colab_type": "code",
        "outputId": "e3f1ce96-815e-4cf7-f530-fda9f79285a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "x = tf.random.uniform((3,),minval=1,maxval=25,dtype=tf.dtypes.int32)\n",
        "y = tf.random.uniform((3,),minval=1,maxval=25,dtype=tf.dtypes.int32)\n",
        "tf.print('x: ', x)\n",
        "tf.print('\\n')\n",
        "tf.print('y: ',y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x:  [1 14 17]\n",
            "\n",
            "\n",
            "y:  [19 21 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPJs55HnSz9v",
        "colab_type": "code",
        "outputId": "1b717976-0e16-4b12-f10e-f4d4e16d17b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "tf.print(n_n_Tensor(x,y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-18 -20 -5]\n",
            " [-5 -7 8]\n",
            " [-2 -4 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YsowfbwiFMC",
        "colab_type": "text"
      },
      "source": [
        "# Task-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvEXiAsQiHgy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "60bc5be7-d91b-469b-e1fd-0bb3ffe9f592"
      },
      "source": [
        "from prepare_data import parse_seq\n",
        "import pickle\n",
        "# this is just a datasets of \"bytes\" (not understandable)\n",
        "data = tf.data.TFRecordDataset(\"skp.tfrecords\")\n",
        "\n",
        "\n",
        "#data.padded_batch\n",
        "#batched_data = data.padded_batch(batch_size = 128, drop_remainder=True)\n",
        "# this maps a parser function that properly interprets the bytes over the dataset\n",
        "# (with fixed sequence length 200)\n",
        "# if you change the sequence length in preprocessing you also need to change it here\n",
        "data = data.map(lambda x: parse_seq(x, 200))\n",
        "\n",
        "\n",
        "#batched_categorical_data = data.padded_batch(batch_size=128, padded_shapes=448,padding_values=0, drop_remainder=True)\n",
        "\n",
        "# a map from characters to indices\n",
        "vocab = pickle.load(open(\"skp_vocab\", mode=\"rb\"))\n",
        "vocab_size = len(vocab)\n",
        "# inverse mapping: indices to characters\n",
        "ind_to_ch = {ind: ch for (ch, ind) in vocab.items()}\n",
        "ch_to_ind = {v: k for k, v in ind_to_ch.items()}\n",
        "print(vocab)\n",
        "print(vocab_size)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'I': 1, 'S': 2, 'G': 3, 'b': 4, 'i': 5, 'r': 6, 'n': 7, 'z': 8, '?': 9, 'j': 10, 'q': 11, '\\n': 12, 'h': 13, 'Y': 14, 'l': 15, 'u': 16, ':': 17, 'D': 18, 'p': 19, 'V': 20, ';': 21, '!': 22, 'O': 23, '$': 24, 'B': 25, 'k': 26, 'F': 27, 'X': 28, \"'\": 29, 'w': 30, 'T': 31, 'M': 32, 'P': 33, 'd': 34, 'e': 35, '.': 36, 'o': 37, 'x': 38, 'm': 39, 'L': 40, 'A': 41, 'W': 42, '[': 43, 'g': 44, 'Q': 45, 'K': 46, ' ': 47, 'U': 48, ',': 49, 'Z': 50, '3': 51, ']': 52, 'H': 53, 'a': 54, 'E': 55, 't': 56, 'c': 57, 'N': 58, 'R': 59, 'J': 60, '&': 61, 's': 62, 'C': 63, 'y': 64, 'f': 65, 'v': 66, '-': 67, '<S>': 0}\n",
            "68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJqQQXGckMdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def onehotencode(ds):\n",
        "  \n",
        "  new_data = tf.one_hot(indices = ds, depth = vocab_size)\n",
        "  return new_data;\n",
        "\n",
        "new_data = data.map(onehotencode)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrGlCHLfjFNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batched_vocab_data = data.batch(batch_size=128,drop_remainder=True)\n",
        "batched_onehotencoded_data = new_data.batch(batch_size=128, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS__UYgTkmy9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7d1c456-885e-4f85-8f91-5be1104e8bcb"
      },
      "source": [
        "cnt = 0\n",
        "for element in data:\n",
        "  cnt = cnt+1\n",
        "print(cnt)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRhC_vUPkusV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_decoder_state_fixed = tf.Variable(tf.keras.initializers.GlorotNormal(seed = 1)(shape=[128,63]))\n",
        "previous_decoder_state_fixed = tf.Variable(tf.keras.initializers.GlorotNormal(seed = 1)(shape=[128,63]))\n",
        "current_encoder_state = tf.Variable(tf.keras.initializers.GlorotNormal(seed = 1)(shape=[128,63]))\n",
        "unscaled_attention_matrix = tf.Variable(tf.keras.initializers.GlorotNormal(seed = 1)(shape=[128,200]))\n",
        "softmax_attention_matrix = tf.Variable(tf.keras.initializers.GlorotNormal(seed = 1)(shape=[128,200]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FErVKeuNk3hr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "54396908-0113-4b56-a88e-e7d96375a0b1"
      },
      "source": [
        "previous_decoder_state_fixed"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(128, 63) dtype=float32, numpy=\n",
              "array([[ 0.01473352, -0.05735376,  0.07342789, ...,  0.09645282,\n",
              "         0.0628942 ,  0.18157996],\n",
              "       [-0.01305565, -0.04977272,  0.12497865, ...,  0.05449903,\n",
              "        -0.18177864, -0.06606366],\n",
              "       [ 0.01745264, -0.21106663, -0.03510231, ..., -0.12910882,\n",
              "        -0.07065466, -0.04943841],\n",
              "       ...,\n",
              "       [ 0.07512955,  0.02983235, -0.08212686, ..., -0.03503273,\n",
              "        -0.07772417,  0.12510055],\n",
              "       [ 0.02088889,  0.19565317,  0.06373518, ...,  0.04682589,\n",
              "        -0.07369351, -0.19658963],\n",
              "       [-0.18037029, -0.11600257, -0.01586506, ..., -0.07738629,\n",
              "         0.03209957,  0.07263009]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbgHnaBzk7IB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30f45ced-b854-45d8-a57e-e423ccc97e72"
      },
      "source": [
        "time_steps=200\n",
        "#Pick the 4th timestep decoder state of dimension [128, 1]\n",
        "for batch_num, (x_batch_train, val_data) in enumerate(zip(batched_onehotencoded_data,batched_vocab_data) ):\n",
        "  print(\"===== batch number: {}\".format(batch_num))\n",
        "  for time_step in range(time_steps-1):\n",
        "    if(time_step == 4):\n",
        "      previous_decoder_state_fixed = val_data[:, time_step]\n",
        "    #encoder_state_at_current_time_step = x_batch_train[:, time_step, :]\n",
        "    #print(\"shape of each time slice: {} \".format(x_t.shape))\n",
        "    #lbl_batch = val_data[:, time_step+1]\n",
        "  break;"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== batch number: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH4fdCculIbZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7ce47fc3-ae4a-49dd-e264-ea0fe208cf65"
      },
      "source": [
        "previous_decoder_state_fixed"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
              "array([62,  7, 35,  4, 19, 12,  6, 37, 35, 35, 27, 54, 56, 16,  7, 35,  6,\n",
              "       62, 64, 37, 47,  5, 65, 13, 35, 15, 35, 47,  6, 57, 34, 35, 54, 47,\n",
              "       56, 32, 35, 56, 47, 47, 35, 13, 14, 47,  7, 47, 62, 47,  5, 55, 56,\n",
              "       54, 62, 36,  6, 32, 47, 16,  2, 12,  5, 13,  6, 63, 13, 37, 35, 37,\n",
              "       56,  7, 62,  6, 54,  2, 57, 15, 19, 56, 30,  7, 49, 13, 47, 16, 62,\n",
              "       35, 37, 16, 47, 12, 21, 41, 12, 56, 15, 39,  7, 49,  1,  1, 16, 64,\n",
              "       47, 58, 35, 31,  6, 13, 47, 54, 37, 12, 42, 47,  6, 13, 35, 56,  1,\n",
              "       47, 47, 30, 57, 44, 47, 30, 35, 47], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IFlC8ZnlKzs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "bc0b8263-b797-4408-ab10-3070227ee811"
      },
      "source": [
        "onehotencoded_prev_decoder_state = onehotencode(previous_decoder_state_fixed)\n",
        "onehotencoded_prev_decoder_state"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 68), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCF1YR_NlNik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "4e6be42f-9e21-4037-b133-5c4a554f5a12"
      },
      "source": [
        "time_steps=200\n",
        "output_list = []\n",
        "for batch_num, (x_batch_train, val_data) in enumerate(zip(batched_onehotencoded_data,batched_vocab_data) ):\n",
        "  print(\"===== batch number: {}\".format(batch_num))\n",
        "  for time_step in range(time_steps):\n",
        "    #(128 * 68) dot product (68 * 128) ==> (128, 128)\n",
        "    curr_timestep_attention_onehot = tf.matmul(a=x_batch_train[:,time_step,:], b=onehotencoded_prev_decoder_state, transpose_b=True)\n",
        "\n",
        "    #Printing some stuff for checking\n",
        "    #print(curr_timestep_attention_onehot)\n",
        "    #print(tf.math.reduce_sum(curr_timestep_attention_onehot, axis=1, keepdims=False, name=None))\n",
        "\n",
        "    #Convert the onehot encoded output to categorical for attention\n",
        "    #(128 * 128) === reduce sum on axis 1 to check attention inside same record, using axis zero would take cross records sum\n",
        "    # (128 * 128) ===> (128 * 1) ==> one attention value per record per timestep\n",
        "    output_list.append(tf.math.reduce_sum(curr_timestep_attention_onehot, axis=1, keepdims=False, name=None))\n",
        "    \n",
        "  unscaled_outputs = tf.stack(output_list,axis = 1)\n",
        "  print(\"====== unscaled thing =============\")\n",
        "  print(unscaled_outputs)\n",
        "  print()\n",
        "  print(\" ===============. softmax thing ===========\")\n",
        "  softmax_output = tf.nn.softmax(unscaled_outputs, axis=1)\n",
        "  print(softmax_output)\n",
        "  print()\n",
        "  print(\"======== check whether softmax adds to one for final check, it adds to ne approx(numerical multiplier issues in matmul) ===========\")\n",
        "  print(tf.reduce_sum(softmax_output, axis=1))\n",
        "\n",
        "  #Print the below to check that softmax across axis = 0 doesn't sum to one for final check\n",
        "  #print(tf.reduce_sum(softmax_output, axis=0))\n",
        "  break;"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== batch number: 0\n",
            "====== unscaled thing =============\n",
            "tf.Tensor(\n",
            "[[ 0.  1.  3. ... 18.  2.  6.]\n",
            " [ 0.  5. 18. ...  8. 18.  3.]\n",
            " [ 0.  8. 18. ...  3.  1. 18.]\n",
            " ...\n",
            " [ 0.  6.  8. ...  5.  5.  2.]\n",
            " [ 0. 14.  6. ... 14.  5.  8.]\n",
            " [ 0. 18.  5. ...  6.  0. 18.]], shape=(128, 200), dtype=float32)\n",
            "\n",
            " ===============. softmax thing ===========\n",
            "tf.Tensor(\n",
            "[[6.7922040e-10 1.8463124e-09 1.3642507e-08 ... 4.4597588e-02\n",
            "  5.0187978e-09 2.7401705e-07]\n",
            " [4.8667026e-10 7.2228261e-08 3.1954750e-02 ... 1.4507434e-06\n",
            "  3.1954750e-02 9.7750332e-09]\n",
            " [5.7840488e-10 1.7242006e-06 3.7978046e-02 ... 1.1617574e-08\n",
            "  1.5722674e-09 3.7978046e-02]\n",
            " ...\n",
            " [5.2054844e-10 2.1000422e-07 1.5517329e-06 ... 7.7256232e-08\n",
            "  7.7256232e-08 3.8463615e-09]\n",
            " [5.1795140e-10 6.2289054e-04 2.0895649e-07 ... 6.2289054e-04\n",
            "  7.6870798e-08 1.5439913e-06]\n",
            " [4.7133214e-10 3.0947652e-02 6.9951888e-08 ... 1.9014895e-07\n",
            "  4.7133214e-10 3.0947652e-02]], shape=(128, 200), dtype=float32)\n",
            "\n",
            "======== check whether softmax adds to one for final check, it adds to ne approx(numerical multiplier issues in matmul) ===========\n",
            "tf.Tensor(\n",
            "[1.         1.0000001  1.0000001  1.0000001  1.         0.99999994\n",
            " 1.0000001  0.99999994 0.99999994 0.9999999  1.         1.\n",
            " 0.9999999  1.         0.99999994 1.         1.         1.0000002\n",
            " 1.         1.         1.         1.         0.9999998  1.\n",
            " 0.99999994 1.0000001  1.0000001  1.         1.         0.9999999\n",
            " 1.         1.         1.         1.         0.99999994 0.9999999\n",
            " 0.9999999  1.0000001  0.9999999  0.99999994 1.0000001  1.\n",
            " 1.0000001  1.         1.0000001  0.9999999  1.         0.99999994\n",
            " 1.         0.99999994 1.         0.99999994 1.         1.\n",
            " 1.0000001  1.         1.         1.         1.0000001  1.\n",
            " 1.         1.         1.0000001  0.9999999  0.99999994 1.\n",
            " 1.         1.         0.9999999  1.         1.         1.0000001\n",
            " 0.99999994 0.9999999  0.9999999  1.         0.99999994 1.\n",
            " 1.         1.         1.         0.99999994 1.         1.\n",
            " 1.0000001  1.         1.         0.99999994 1.         1.\n",
            " 0.99999994 1.0000002  1.         1.         1.         0.99999994\n",
            " 1.         1.         1.0000001  1.0000001  0.99999994 1.\n",
            " 1.         1.         0.99999994 0.99999994 1.0000001  1.\n",
            " 1.         0.99999994 0.99999994 1.         0.9999999  1.0000001\n",
            " 1.         1.         0.99999994 1.         1.0000001  1.\n",
            " 1.0000001  1.0000001  1.         1.0000002  1.0000002  0.9999999\n",
            " 1.         1.        ], shape=(128,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrpKeJMLlSVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}